import asyncio
import pandas as pd
import json
import os
import base64
from datetime import datetime
from bilibili_api import user, channel_series, video, Credential, sync

# --- æ–°å¢ï¼šåŠ å¯†åº“ ---
from cryptography.fernet import Fernet, InvalidToken
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC

# å¼•å…¥ openpyxl ç”¨äºæ ·å¼è°ƒæ•´
from openpyxl.styles import Border, Side, Alignment, Font

# --- 1. å®‰å…¨ Cookie ç®¡ç†æ¨¡å— ---
COOKIE_FILE = "cookies.bin"  # æ”¹ä¸ºäºŒè¿›åˆ¶æ–‡ä»¶

def _derive_key(password: str, salt: bytes) -> bytes:
    """æ ¹æ®å¯†ç å’Œç›å€¼ç”Ÿæˆå¯†é’¥"""
    kdf = PBKDF2HMAC(
        algorithm=hashes.SHA256(),
        length=32,
        salt=salt,
        iterations=100000,
    )
    return base64.urlsafe_b64encode(kdf.derive(password.encode()))

def save_cookies_encrypted(sessdata, bili_jct, buvid3):
    """åŠ å¯†ä¿å­˜ Cookies"""
    data = json.dumps({"SESSDATA": sessdata, "BILI_JCT": bili_jct, "BUVID3": buvid3})
    
    while True:
        pwd = input("ğŸ” è¯·è®¾ç½®ä¸€ä¸ªè¯»å–å¯†ç  (ç”¨äºåŠ å¯†æœ¬åœ°æ–‡ä»¶): ").strip()
        if pwd:
            break
        print("å¯†ç ä¸èƒ½ä¸ºç©ºï¼")

    # 1. ç”Ÿæˆéšæœºç›å€¼
    salt = os.urandom(16)
    # 2. ç”Ÿæˆå¯†é’¥
    key = _derive_key(pwd, salt)
    f = Fernet(key)
    # 3. åŠ å¯†æ•°æ®
    encrypted_data = f.encrypt(data.encode())
    
    # 4. ä¿å­˜ï¼šå‰16å­—èŠ‚æ˜¯ç›å€¼ï¼Œåé¢æ˜¯åŠ å¯†å†…å®¹
    with open(COOKIE_FILE, "wb") as f_out:
        f_out.write(salt + encrypted_data)
        
    print(f"ğŸ’¡ å‡­æ®å·²åŠ å¯†å¹¶ä¿å­˜è‡³ {COOKIE_FILE}")

def load_cookies_encrypted():
    """è§£å¯†è¯»å– Cookies"""
    if not os.path.exists(COOKIE_FILE):
        return None

    print(f"ğŸ“‚ å‘ç°åŠ å¯†çš„å‡­æ®æ–‡ä»¶: {COOKIE_FILE}")
    pwd = input("ğŸ”‘ è¯·è¾“å…¥å¯†ç ä»¥è§£å¯†: ").strip()

    try:
        with open(COOKIE_FILE, "rb") as f_in:
            file_content = f_in.read()
        
        # æå–ç›å€¼ (å‰16å­—èŠ‚) å’Œ å¯†æ–‡
        salt = file_content[:16]
        encrypted_data = file_content[16:]
        
        # è¿˜åŸå¯†é’¥
        key = _derive_key(pwd, salt)
        f = Fernet(key)
        
        # è§£å¯†
        decrypted_data = f.decrypt(encrypted_data)
        return json.loads(decrypted_data.decode())

    except InvalidToken:
        print("âŒ å¯†ç é”™è¯¯ï¼æ— æ³•è§£å¯†ã€‚")
        return None
    except Exception as e:
        print(f"âŒ æ–‡ä»¶æŸåæˆ–è¯»å–é”™è¯¯: {e}")
        return None

async def get_credential():
    # å°è¯•åŠ è½½æœ¬åœ°åŠ å¯†å‡­æ®
    cookies = load_cookies_encrypted()
    
    if cookies:
        print("ğŸ”“ è§£å¯†æˆåŠŸï¼Œæ­£åœ¨éªŒè¯æœ‰æ•ˆæ€§...")
        c = Credential(
            sessdata=cookies['SESSDATA'], 
            bili_jct=cookies['BILI_JCT'], 
            buvid3=cookies['BUVID3']
        )
        try:
            if await c.check_valid(): 
                print("âœ… ç™»å½•éªŒè¯é€šè¿‡ï¼")
                return c
            else:
                print("âš ï¸ æœ¬åœ°å‡­æ®å·²è¿‡æœŸã€‚")
        except: 
            print("âš ï¸ ç½‘ç»œè¿æ¥å¤±è´¥æˆ–å‡­æ®æ— æ•ˆã€‚")
    
    # å¦‚æœæ²¡æœ‰æ–‡ä»¶ã€å¯†ç é”™è¯¯æˆ–å‡­æ®è¿‡æœŸï¼Œé‡æ–°è¾“å…¥
    print("\n" + "="*40)
    print("ğŸ†• éœ€è¦é‡æ–°ç™»å½• (è·å–æ–¹å¼ï¼šæµè§ˆå™¨ F12 -> Application -> Cookies)")
    s = input("SESSDATA: ").strip()
    j = input("bili_jct: ").strip()
    b = input("buvid3: ").strip()
    
    # éªŒè¯æ–°è¾“å…¥çš„å‡­æ®
    c = Credential(sessdata=s, bili_jct=j, buvid3=b)
    if await c.check_valid():
        save_cookies_encrypted(s, j, b) # ä¿å­˜æ—¶ä¼šè¦æ±‚è®¾ç½®å¯†ç 
        return c
    else:
        print("âŒ è¾“å…¥çš„ Cookies æ— æ•ˆï¼Œè¯·æ£€æŸ¥ã€‚")
        return None

# --- 2. æ ¸å¿ƒæŠ“å–é€»è¾‘ (ä¿æŒåŠŸèƒ½ä¸å˜) ---

async def fetch_live_series_data(credential, uid, sid, year):
    print(f"\nğŸ“º [1/3] æ­£åœ¨æ‰«æç›´æ’­åˆé›† (ID: {sid})...")
    cs = channel_series.ChannelSeries(uid=uid, id_=sid, type_=channel_series.ChannelSeriesType.SERIES, credential=credential)
    
    live_data = []
    live_bvids = set()
    page = 1
    series_name = "æœªå‘½ååˆé›†"
    
    try:
        meta = await cs.get_meta()
        series_name = meta.get('meta', {}).get('name', 'æœªå‘½ååˆé›†')
        print(f"   åˆé›†åç§°: {series_name}")

        while True:
            res = await cs.get_videos(pn=page, ps=30)
            archives = res.get('archives', [])
            if not archives: break
            
            for v in archives:
                pub_ts = v.get('pubdate', v.get('ctime'))
                dt = datetime.fromtimestamp(pub_ts)
                if year and dt.year != year: continue
                
                bvid = v['bvid']
                live_bvids.add(bvid)
                
                stat = v.get('stat', {})
                view = stat.get('view', 0)
                like = stat.get('like', 0)
                coin = stat.get('coin', 0)
                fav = stat.get('favorite', 0)
                triple = like + coin + fav
                
                live_data.append({
                    "æ—¥æœŸ": dt.strftime("%Y-%m-%d"),
                    "æ ‡é¢˜": v['title'],
                    "ç±»å‹": "ç›´æ’­å›æ”¾",
                    "æ—¶é•¿(å°æ—¶)": round(v.get('duration', 0) / 3600, 2),
                    "æ’­æ”¾": view,
                    "ç‚¹èµ": like,
                    "æŠ•å¸": coin,
                    "æ”¶è—": fav,
                    "ä¸‰è¿": triple,
                    "BVå·": bvid,
                    "é“¾æ¥": f"https://www.bilibili.com/video/{bvid}"
                })
            
            if page * 30 >= res.get('page', {}).get('count', 0): break
            page += 1
            print(f"\r   å·²è·å– {len(live_data)} æ¡å›æ”¾æ•°æ®...", end="")
            await asyncio.sleep(0.2)
            
    except Exception as e:
        print(f"\nâŒ è·å–åˆé›†å¤±è´¥: {e}")
    
    print(f"\n   âœ… ç›´æ’­å›æ”¾æ‰«æå®Œæ¯•ï¼Œå…± {len(live_data)} æ¡ã€‚")
    return live_data, live_bvids, series_name

async def fetch_user_uploads(credential, uid, year, exclude_bvids):
    print(f"\nğŸ“¹ [2/3] æ­£åœ¨æ‰«æä¸»é¡µæŠ•ç¨¿ (æ’é™¤ç›´æ’­åˆé›†)...")
    u = user.User(uid=uid, credential=credential)
    video_data = []
    page = 1
    is_finish = False
    
    while not is_finish:
        res = await u.get_videos(pn=page, ps=30)
        vlist = res.get('list', {}).get('vlist', [])
        if not vlist: break

        for v in vlist:
            dt = datetime.fromtimestamp(v['created'])
            if year:
                if dt.year > year: continue
                if dt.year < year: 
                    is_finish = True
                    break
            
            bvid = v['bvid']
            if bvid in exclude_bvids: continue 
            
            print(f"\r   æ­£åœ¨è·å–è¯¦æƒ…: {v['title'][:15]}...", end="")
            try:
                v_obj = video.Video(bvid=bvid, credential=credential)
                info = await v_obj.get_info()
                stat = info['stat']
                
                video_data.append({
                    "æ—¥æœŸ": dt.strftime("%Y-%m-%d"),
                    "æ ‡é¢˜": v['title'],
                    "ç±»å‹": "æ™®é€šæŠ•ç¨¿",
                    "æ—¶é•¿(å°æ—¶)": round(info['duration'] / 3600, 2),
                    "æ’­æ”¾": stat['view'],
                    "ç‚¹èµ": stat['like'],
                    "æŠ•å¸": stat['coin'],
                    "æ”¶è—": stat['favorite'],
                    "ä¸‰è¿": stat['like'] + stat['coin'] + stat['favorite'],
                    "BVå·": bvid,
                    "é“¾æ¥": f"https://www.bilibili.com/video/{bvid}"
                })
                await asyncio.sleep(0.3)
            except Exception as e:
                print(f" (è·³è¿‡: {e})", end="")
        
        if is_finish: break
        page += 1
        
    print(f"\n   âœ… æ™®é€šæŠ•ç¨¿æ‰«æå®Œæ¯•ï¼Œå…± {len(video_data)} æ¡ã€‚")
    return video_data

# --- 3. æ ·å¼è°ƒæ•´å‡½æ•° ---
def style_excel(writer, sheet_name, title_text):
    worksheet = writer.sheets[sheet_name]
    
    # æ’å…¥å¹´ä»½æ ‡é¢˜è¡Œ
    worksheet.insert_rows(1)
    worksheet['A1'] = title_text
    worksheet.merge_cells('A1:C1')
    
    # æ ·å¼å®šä¹‰
    thin_border = Border(left=Side(style='thin'), right=Side(style='thin'), 
                         top=Side(style='thin'), bottom=Side(style='thin'))
    title_font = Font(name='å¾®è½¯é›…é»‘', size=12, bold=False)  
    header_font = Font(name='å¾®è½¯é›…é»‘', size=11, bold=True)   
    
    # åº”ç”¨é¡¶éƒ¨æ ‡é¢˜æ ·å¼
    cell_title = worksheet['A1']
    cell_title.alignment = Alignment(horizontal='center', vertical='center')
    cell_title.font = title_font
    cell_title.border = thin_border
    worksheet['B1'].border = thin_border
    worksheet['C1'].border = thin_border

    # éå†æ‰€æœ‰è¡Œ
    for row in worksheet.iter_rows(min_row=2):
        cell_a = row[0]
        cell_b = row[1]
        
        for cell in row:
            cell.border = thin_border
            cell.alignment = Alignment(vertical='center')

        # åˆå¹¶åˆ†éš”è¡Œ (A-C)
        val = str(cell_a.value) if cell_a.value else ""
        if ("---" in val or "æ¦œ" in val) and cell_b.value == "":
            worksheet.merge_cells(start_row=cell_a.row, start_column=1, end_row=cell_a.row, end_column=3)
            cell_a.font = header_font
            cell_a.alignment = Alignment(horizontal='center', vertical='center')
        
        # è¡¨å¤´è¡Œ
        if cell_a.row == 2:
            for cell in row:
                cell.font = header_font
                cell.alignment = Alignment(horizontal='center', vertical='center')

    # åˆ—å®½
    worksheet.column_dimensions['A'].width = 40
    worksheet.column_dimensions['B'].width = 15
    worksheet.column_dimensions['C'].width = 45

# --- 4. è¾…åŠ©å‡½æ•° ---
def get_top_n(data_list, key, n=5):
    sorted_list = sorted(data_list, key=lambda x: x[key], reverse=True)
    return sorted_list[:n]

async def generate_report():
    print("="*50)
    print("   Bilibili UPä¸»å¹´åº¦æ•°æ®ç»¼åˆåˆ†æå·¥å…· (åŠ å¯†ç‰ˆ)")
    print("="*50)

    credential = await get_credential()
    if not credential: return

    try:
        uid = int(input("1. è¾“å…¥UPä¸» UID: ").strip())
        sid = int(input("2. è¾“å…¥ç›´æ’­å›æ”¾åˆé›† ID (sid): ").strip())
        year_in = input("3. ç»Ÿè®¡å¹´ä»½ (ä¾‹å¦‚ 2025ï¼Œå›è½¦ç»Ÿè®¡å…¨éƒ¨): ").strip()
        target_year = int(year_in) if year_in.isdigit() else None
    except ValueError:
        print("âŒ è¾“å…¥é”™è¯¯ã€‚")
        return

    # è·å–æ•°æ®
    u = user.User(uid=uid, credential=credential)
    try:
        u_info = await u.get_user_info()
        nickname = u_info['name']
        u_rel = await u.get_relation_info()
        fans = u_rel['follower']
    except Exception as e:
        print(f"âŒ è·å–UPä¸»ä¿¡æ¯å¤±è´¥ï¼Œå¯èƒ½æ˜¯å‡­æ®å¤±æ•ˆ: {e}")
        return

    live_list, live_bvids, series_name = await fetch_live_series_data(credential, uid, sid, target_year)
    video_list = await fetch_user_uploads(credential, uid, target_year, live_bvids)
    all_data = live_list + video_list
    
    if not all_data:
        print("âŒ æ— æ•°æ®ã€‚")
        return

    # è®¡ç®—
    df_all = pd.DataFrame(all_data)
    total_likes = df_all['ç‚¹èµ'].sum()
    total_coins = df_all['æŠ•å¸'].sum()
    total_favs = df_all['æ”¶è—'].sum()
    
    live_hours = sum(i['æ—¶é•¿(å°æ—¶)'] for i in live_list)
    live_count = len(live_list)
    live_likes = sum(i['ç‚¹èµ'] for i in live_list)
    
    video_hours = sum(i['æ—¶é•¿(å°æ—¶)'] for i in video_list)
    video_count = len(video_list)
    video_likes = sum(i['ç‚¹èµ'] for i in video_list)

    dates = pd.to_datetime(df_all['æ—¥æœŸ'])
    freq_str = "N/A"
    if len(dates) > 1:
        avg_days = round((dates.max() - dates.min()).days / len(dates), 1)
        freq_str = f"å¹³å‡æ¯ {avg_days} å¤©æ›´æ–°"

    # æ„é€  Rows
    summary_rows = [
        ["UPä¸»æ˜µç§°", nickname, ""],
        ["UID", uid, ""],
        ["ç»Ÿè®¡å¹´ä»½", target_year or "å…¨éƒ¨å†å²", ""],
        ["ç²‰ä¸æ•°", fans, ""],
        ["æ€»è·èµæ•°", total_likes, ""],
        ["æ€»æŠ•å¸æ•°", total_coins, ""],
        ["æ€»æ”¶è—æ•°", total_favs, ""],
        ["æ›´æ–°é¢‘ç‡", freq_str, ""],
        
        ["--- ç›´æ’­å›æ”¾æ•°æ® ---", "", ""],
        ["å›æ”¾åˆé›†åç§°", series_name, ""],
        ["ç›´æ’­åœºæ¬¡", live_count, ""],
        ["ç›´æ’­æ€»æ—¶é•¿ (å°æ—¶)", round(live_hours, 2), ""],
        ["åœºå‡æ—¶é•¿ (å°æ—¶)", round(live_hours/live_count, 2) if live_count else 0, ""],
        ["å›æ”¾æ€»è·èµ", live_likes, ""],
        
        ["--- æ™®é€šæŠ•ç¨¿æ•°æ® ---", "", ""],
        ["æŠ•ç¨¿æ•°é‡", video_count, ""],
        ["æŠ•ç¨¿æ€»æ—¶é•¿ (å°æ—¶)", round(video_hours, 2), ""],
        ["æŠ•ç¨¿æ€»è·èµ", video_likes, ""]
    ]

    # æ·»åŠ æ¦œå•
    rankings_config = [
        ("--- æ’­æ”¾æ¦œ Top 5 (æ ‡é¢˜ | æ’­æ”¾é‡) ---", "æ’­æ”¾"),
        ("--- ç‚¹èµæ¦œ Top 5 (æ ‡é¢˜ | ç‚¹èµæ•°) ---", "ç‚¹èµ"),
        ("--- æŠ•å¸æ¦œ Top 5 (æ ‡é¢˜ | æŠ•å¸æ•°) ---", "æŠ•å¸"),
        ("--- æ”¶è—æ¦œ Top 5 (æ ‡é¢˜ | æ”¶è—æ•°) ---", "æ”¶è—"),
        ("--- ä¸‰è¿æ¦œ Top 5 (æ ‡é¢˜ | ç»¼åˆåˆ†) ---", "ä¸‰è¿"),
    ]

    for title, key in rankings_config:
        summary_rows.append([title, "", ""])
        top_list = get_top_n(all_data, key, 5)
        for item in top_list:
            summary_rows.append([item['æ ‡é¢˜'], item[key], item['é“¾æ¥']])
        if not top_list:
            summary_rows.append(["(æ— æ•°æ®)", 0, ""])

    df_summary = pd.DataFrame(summary_rows, columns=["ç»´åº¦", "æ•°å€¼", "é“¾æ¥"])

    # å¯¼å‡º
    filename = f"{nickname}_{target_year or 'å…¨éƒ¨'}_å¹´åº¦æŠ¥å‘Š.xlsx"
    with pd.ExcelWriter(filename, engine='openpyxl') as writer:
        df_summary.to_excel(writer, sheet_name="å¹´åº¦æ±‡æ€»", index=False)
        if live_list: pd.DataFrame(live_list).to_excel(writer, sheet_name="ç›´æ’­å›æ”¾æ˜ç»†", index=False)
        if video_list: pd.DataFrame(video_list).to_excel(writer, sheet_name="æ™®é€šæŠ•ç¨¿æ˜ç»†", index=False)
        
        title_text = str(target_year) if target_year else "å†å²å…¨éƒ¨æ•°æ®"
        style_excel(writer, "å¹´åº¦æ±‡æ€»", title_text)

    print("-" * 40)
    print(f"ğŸ‰ æŠ¥å‘Šç”ŸæˆæˆåŠŸ: {filename}")

if __name__ == "__main__":
    if os.name == 'nt':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    try:
        sync(generate_report())
    except RuntimeError:
        loop = asyncio.get_event_loop()
        if loop.is_running(): asyncio.create_task(generate_report())
        else: loop.run_until_complete(generate_report())